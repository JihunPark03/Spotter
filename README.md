# ğŸ§  Spotter â€” ML based AI Ad Detection Extension

Spotter is a full-stack project that detects whether selected text contains promotional or advertisement-like content.
It combines a Chrome Extension UI, a FastAPI backend, and a dedicated ML inference server powered by a PyTorch model.

The system is designed to be **fast, modular, and continuously improving** through user feedback and periodic model training.

## Warning : it only works with Korean review/text

# Examples
For example, Spotter was tested on the following dining review website (https://www.diningcode.com/profile.php?rid=hAebbrQ1gHyi)

Popup view after pressing 'Analyze' button:
![Popup analysis](assets/screenshots/Screenshot%202026-02-26%20at%2012.12.03.png)

Feedback homepage:
![Progress and summary](assets/screenshots/Screenshot%202026-02-26%20at%2012.12.42.png)

Feedback page (User can rate the text):
![Progress and summary](assets/screenshots/Screenshot%202026-02-26%20at%2012.12.50.png)

---

# ğŸš€ Features

* Detect advertisement probability from highlighted text
* Lightweight API server with caching support
* Dedicated ML server for efficient inference
* Feedback-based training pipeline
* Automatic loading of the latest model version

---

# ğŸ§© Architecture Overview

```
Chrome Extension
        â†“
API Server (FastAPI)
        â†“
ML Server (PyTorch Inference)
        â†“
Model Weights
```

### Why separate API and ML servers?

* API server stays lightweight and responsive
* ML model loads only once inside the ML server
* Training can run independently without stopping the API

---

# ğŸ“ Project Structure

```
Spotter/
â”‚
â”œâ”€â”€ api-server/          # FastAPI backend
â”‚   â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ ml_client.py
â”‚   â””â”€â”€ main.py
â”‚
â”œâ”€â”€ ml-server/           # Model inference server
â”‚   â”œâ”€â”€ inference.py
â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ preprocess.py
â”‚   â””â”€â”€ models/
â”‚        â”œâ”€â”€ model_v1.pth
â”‚        â”œâ”€â”€ model_v2.pth
â”‚        â””â”€â”€ cc.ko.300.bin
â”‚
â”œâ”€â”€ trainer/             # Training pipeline (runs separately)
â”‚   â”œâ”€â”€ train.py
â”‚   â””â”€â”€ build_dataset.py
â”‚
â”œâ”€â”€ extension/           # Chrome extension UI
â”‚
â””â”€â”€ docker-compose.yml
```

---

# âš™ï¸ Tech Stack

**Backend**

* FastAPI
* PostgreSQL (feedback storage)
* Redis or in-memory cache

**Machine Learning**

* PyTorch
* LSTM + Attention model
* FastText embeddings

**Frontend**

* Chrome Extension (Vanilla JS)

---

# ğŸ§ª How It Works

## 1ï¸âƒ£ User selects text

The extension sends:

```
POST /detect-ad
```

---

## 2ï¸âƒ£ API Server

The API server:

* Creates a cache key
* Checks Redis or local cache
* Calls ML server if result is not cached

```
prob = request_inference(text)
```

---

## 3ï¸âƒ£ ML Server

The ML server:

* Loads the latest model in `models/`
* Preprocesses the text
* Converts tokens into embedding matrices
* Runs PyTorch inference

Output:

```
prob_ad = sigmoid(logit)
```

---

# ğŸ”„ Training Pipeline (Trainer)

Spotter improves over time using feedback collected from users.

The **trainer is not always running** â€” it is executed manually or periodically when enough new feedback has been collected.

Typical workflow:

```
User Feedback â†’ Database
        â†“
trainer/build_dataset.py
        â†“
trainer/train.py
        â†“
New model_vX.pth generated
```

### ğŸŸ¡ When does the trainer run?

The trainer is usually executed when:

* A certain number of new feedback samples exist in the database
* You want to refresh the model with new data
* During scheduled training (cron job / manual run)

Example:

```
cd trainer
python -m train
```

After training:

* A new `model_vX.pth` file is saved
* The ML server automatically detects and uses the newest model

No API restart is required.

---

# âš¡ Setup Guide

## 1. Clone Repository

```
git clone https://github.com/yourname/spotter.git
cd spotter
```

---

## 2. Start API Server

```
cd api-server
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
uvicorn main:app --port 8000
```

---

## 3. Start ML Server

```
cd ml-server
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
uvicorn main:app --port 8001
```

---

## 4. Redis (Optional)

```
brew install redis
redis-server
```

Environment variables:

```
REDIS_HOST=localhost
REDIS_PORT=6379
```

If Redis is unavailable, Spotter falls back to an in-memory cache.

---

# ğŸ§© API Endpoint

## Detect Advertisement

```
POST /detect-ad
```

Request:

```
{
  "text": "example review text"
}
```

Response:

```
{
  "prob_ad": 82.3,
  "is_ad": true,
  "cached": false
}
```

---

# ğŸ”„ Model Versioning

Models are stored as:

```
models/model_v1.pth
models/model_v2.pth
...
```

The ML server automatically loads the newest version based on filename.

---

# ğŸŒ Deployment Notes

Recommended setup:

* API Server â†’ GCP VM
* ML Server â†’ Same VM or separate instance
* Redis â†’ Local Redis or Memorystore

---

# ğŸ‘¨â€ğŸ’» Author

Jihun Park
Computer Science & Communication Engineering
Waseda University

---

# â­ Motivation

Spotter explores how real user interaction and feedback can be integrated into a practical AI pipeline, combining lightweight backend engineering with an evolving machine learning model.
