{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d79f7eb8e89540b587e65b54cd796184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_763ecae5c32348148a3251652d331309",
              "IPY_MODEL_0067cafde56f4135a1fd9b4956f2aabb",
              "IPY_MODEL_e539bf5546714878ad500292f078d569"
            ],
            "layout": "IPY_MODEL_9fcafbcf7cd24a84b230b72a251dd359"
          }
        },
        "763ecae5c32348148a3251652d331309": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9db2fee3c2c4c6182970a975eb9e59d",
            "placeholder": "​",
            "style": "IPY_MODEL_673f745857e4498d85ed31b2654265a5",
            "value": "Embedding: 100%"
          }
        },
        "0067cafde56f4135a1fd9b4956f2aabb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d0d67da7c5c4e148b1a24129c9aa4a5",
            "max": 2080,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d60563109b3343d09cce94f1adef9ffe",
            "value": 2080
          }
        },
        "e539bf5546714878ad500292f078d569": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_269832265c394a61baf23c4f6f58f82b",
            "placeholder": "​",
            "style": "IPY_MODEL_a55d92e4312d4d0e8c31a7beb15386cd",
            "value": " 2080/2080 [02:22&lt;00:00, 41.85it/s]"
          }
        },
        "9fcafbcf7cd24a84b230b72a251dd359": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9db2fee3c2c4c6182970a975eb9e59d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "673f745857e4498d85ed31b2654265a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d0d67da7c5c4e148b1a24129c9aa4a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d60563109b3343d09cce94f1adef9ffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "269832265c394a61baf23c4f6f58f82b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a55d92e4312d4d0e8c31a7beb15386cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bst56GU78w8G",
        "outputId": "f8a1c937-a034-4517-f6e3-2d35e0d13b36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tGPk8-T7SxhG",
        "outputId": "10f44ee8-7433-451e-fa4c-0e79c4d64fa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fasttext) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fasttext) (2.0.2)\n",
            "Collecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading jpype1-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from konlpy) (5.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from JPype1>=0.7.0->konlpy) (24.2)\n",
            "Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jpype1-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (494 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.1/494.1 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.3-cp311-cp311-linux_x86_64.whl size=4313503 sha256=be9ccd5c2219019cdac7001e5f5fcaf3eceae6dce97aa3907178a0ede16488e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/4f/35/5057db0249224e9ab55a513fa6b79451473ceb7713017823c3\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, JPype1, konlpy, fasttext\n",
            "Successfully installed JPype1-1.5.2 fasttext-0.9.3 konlpy-0.6.0 pybind11-2.13.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ▒▒ 0) 환경 설정 ▒▒──────────────────────────────────────────\n",
        "import os, json, re, pickle, random\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import fasttext\n",
        "from konlpy.tag import Okt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "\n",
        "# 작업 경로들 (필요하면 수정)\n",
        "DATA_PATH   = Path(\"/content/drive/MyDrive/25-1-Bridge/combined_labeled_reviews.json\")   # ← 새 JSON\n",
        "FT_MODEL    = Path(\"/content/drive/MyDrive/25-1-Bridge/cc.ko.300.bin\")\n",
        "SAVE_DIR    = Path(\"/content/drive/MyDrive/25-1-Bridge/OUTPUT\"); SAVE_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# 학습 하이퍼파라미터\n",
        "BATCH_SIZE      = 128\n",
        "PAD_LEN         = 800      # 문장 당 단어 벡터 수\n",
        "EMB_DIM         = 300\n",
        "HIDDEN_DIM      = 32\n",
        "EPOCHS          = 1000\n",
        "PATIENCE        = 100      # early lr-decay\n",
        "LR              = 1e-4\n",
        "\n",
        "# ▒▒ 1) 데이터 로드 ▒▒────────────────────────────────────────\n",
        "def load_json(path: Path):\n",
        "    \"\"\"새 포맷: [{\"review\": \"...\", \"label\": \"ad\"|\"non_ad\"}, ...]\"\"\"\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as fp:\n",
        "        data = json.load(fp)\n",
        "    df = pd.DataFrame(data)\n",
        "    # label 매핑: ad →1, non_ad →0\n",
        "    df[\"label\"] = df[\"label\"].map({\"ad\": 1, \"non_ad\": 0})\n",
        "    return df\n",
        "\n",
        "df = load_json(DATA_PATH)\n",
        "print(\"총 샘플:\", len(df))\n",
        "\n",
        "# ▒▒ 2) 불용어 사전 구축 ▒▒───────────────────────────────────\n",
        "# 2-1) 사용자 수동 리스트\n",
        "STOPWORDS = ['이', '그', '저', '은', '는', '이었', '합니다', '그리고', '하지만', '을', '를', '에', '의', '가',\n",
        "             '~', ':)', '!', ')', '(', '.', ',', '쪽지', '공감', '스크랩', '익명', '(?)', '?', '!', '~~',\n",
        "             '후기', '연세대', '서문', '신고', '・', 'URL', '복사', '선택', '추천', '네이버', '리뷰', '식당',\n",
        "             '음식', '랑', '와', '으로', '으로는', '-', '이랑', '야', '옆', '까지', '께서', '도', '앞', '지만',\n",
        "             '그런데', '사실', '이라', '내', \"'\", '다만', ':', '..', '보다', '너무', '더', '진짜', '개', '과',\n",
        "             '좀', '들', '한', '님', '하고', '든', '전', '계속', '인데', '이라는', '법', '+', '쪽', '음', '아',\n",
        "             '정도', '원', '맵', '못', '이었고', '꽤', '총', '평', '이고', '분', '세', '조금', '보니', '으로서',\n",
        "             '아래', '쯤', '본문', '추가', '이웃', '여기', '주위', '극', '대', '노', '대박', '모', '것', '밖에',\n",
        "             '그냥', '에서도', '할', '근대', '같이', '처럼', '신촌', '고서', '평소', '네', '번째', '별로', '수도',\n",
        "             '우리', '로', '안', '글', '거', '나', '집', '다', 'ㅎㅎ', 'ㅎ', 'ㅋ', '짜리', '기타', '돼서', '느낌',\n",
        "             '적', '본', 'ㅋㅋ', '방문', '봐서', '상황', '한번', '에서', '해요', '요', '오', '내돈내산', '솔직후기',\n",
        "             '제공', '광고성', '광고', '2024', '2023', '2022', '시간', '분', '전', 'AM', 'PM', 'am', 'pm',\n",
        "             '이용', '위치', '맛집', '시간', '주문', '메뉴', '예약', '영업',\n",
        "             '맛', '근처', '소개', '사진', '위해', '여기', '에서는', '에서',\n",
        "             '곳', '다녀왔어요', '먹었어요', '갔습니다', '합니다', '입니다',\n",
        "             '했습니다', '다음', '누구', '특히', '때', '있는', '매일',\n",
        "             '가능', '추천', '검색', '잘', '다', '된', '중', '와서',\n",
        "             '맛있는', '수', '곳', '있는', '해서', '직접', '새로',\n",
        "             '하고', '하시', '저녁', '점심', '아침',\n",
        "             '가능한', '정말', '많은', '모두', '보다는',  '하는',\n",
        "             '해주시는', '휴무', '매주', '필요', '좋아요', '많아서', '다녀오고',\n",
        "             '게', '는', '을', '를', '이', '가', '의', '에', '와', '과',\n",
        "             '로', '으로', '도', '다', '만', '보다', '부터', '그리고',\n",
        "             '또는', '해서', '인데', '이라', '이며', '또', '그', '하지만',\n",
        "             '그래도', '때문에', '이런', '저런', '그런', '더', '까지',\n",
        "             '하면', '든', '요', '하니', '하면서', '으로써', '중에', '처럼','쓰고있다고','때문',\n",
        "             '갈','있어요','이었는데','에는','마다','없이','했어요','있었어요','랬','적고',\n",
        "             '있었기','했는지','참','있고','있도록','되어','라고','좋았요','니당','어떤','리기',\n",
        "             '있었던','리도','잇','하길래','있다','일까','지','되는','아닌','고','D','등','통해',\n",
        "             '데','겸','않고','S','이나','무엇','또한','드립니다','A','하겠습니다','보면','그렇다면',\n",
        "             '있어서','학','라','집니다','면','에는','T','X','니','하는데요','에게','이었네요','듯',\n",
        "             '있','o','set','같아용','자아내죠','건','Instagram','대해','이건','이었습니다',\n",
        "             'Rachadamnoen','보이는','각종','이서','였다','있었습니다','싶은','되어있어서',\n",
        "             '하십니다','였어요','ㅋㅋㅋ','채','OO','ㅡ','그렇게','이서','건가','앗','였어요','저희',\n",
        "             '했을','듬뿍','넘','단체','같네요','메뉴','국물', '도삭면', '백김치', '떡갈비', '팟타이',\n",
        "             '옹심이', '게장', '계란말이', '어묵', '반찬', '만두', '한우', '육전','튀김', '초밥', '국물', '닭발', '목살', '치킨',\n",
        "             '꼬치', '비빔국수', '들깨', '김밥', '해장국', '반찬', '쌈무', '돈까스','닭발', '치킨', '들깨', '장탕', '새우',\n",
        "             '국수', '카츠','김밥', '갈비', '김치', '냉면','인가요','됐습니다','되었더라구요','Mueang','그만','치고는',\n",
        "             '있냐면','인','되어있었다','팅','씩',' ','버거','찐','이렇게','쏙','제','이네요','및','해도','어느','로서','ㄹ','놀',\n",
        "             '뭔','하지','잇다고','였던','따라','합니당','부탁드립니당','이제','끔','꼭','에도','한다는','하','있습니다','스럽게',\n",
        "             '드림다','하신다면','엔','에도','꼭','최고','좋은','같아요','아마','ㅠㅠ','바로','','오늘','딱','함께','이지만',\n",
        "             '외','씩','ERang','naver','뿐','NO','nail','go','ㅎㅎㅎ','위','인','껏','뜨','속','봅니다','크','더욱','려고',\n",
        "             '엄청','좋은','했던','있게','래서','한데','있는데','내내','예요','이니까','이다','역시','굿','층','우삼겹',\n",
        "             '움','덕분','그럼에도','g','이었다','일단','요즘','계란찜','가장','짠','하다','이라고','했다','즈','아주',\n",
        "             '자주','모든','되었습니다','공유','댓글','혹시','갈치','구이','ㅠ','샤브샤브','소반','이에요','middot','라는',\n",
        "             '움','닭갈비','쌈','거야','익히','같았어요','라곤','한테','걸','이었던','서','3','걸','했는데요','싶네요','까요',\n",
        "             '파스타','있다면','있다고','익히','라곤','이었던','라면','멍멍','으로도','했었던','그래서','고고','동안',\n",
        "             'o','꿔','천','아니라','매우','다녀오실수있어용','에까지','서','니까','인지','있으며','죠','K','라면','물론',\n",
        "             'OGQ','me','thumb','나야','겠죠','두','난','에게는','젤루','K','하구요','면서','하는데','될','하기에','껄',\n",
        "             'ㅋㅋㅋㅋㅋ','뭐','d','you','Chang','가츠덮밥','쿠시카츠','미역국','쭈구미','갈비탕','평일','부타동','메론빵',\n",
        "             '껍항정','그리','거기','mp','막국수','돈까스','치즈스틱','모듬전','ㅋㅋㅋㅋ','ᵔ','같은','에요','여','각','라멘',\n",
        "             '다른','보통','갑니당','곱창','연어','이었어요','수육','김치찌개','한다면','하루하루','ㅠㅠㅠ','    ','장어','돼지국밥',\n",
        "             '대로','으','완전','오후','무렵','넉','구','에서만','시','햄버거','피자','쭈꾸미', \"호텔\", \"객실\", \"교통\", \"시설\",\n",
        "             \"오송\", \"강남\", \"남원\", \"서귀포시\", \"장소\", \"터미널\", \"수쿰빗\", \"하카타역\", \"마카오\", \"디럭스\", \"르\", \"홍대\"\n",
        "             ]\n",
        "\n",
        "# 2-2) 모든 날짜·시각 문자열을 불용어에 추가\n",
        "def gen_dates(start=2022, end=2024):\n",
        "    d0, d1 = datetime(start,1,1), datetime(end,12,31)\n",
        "    return [(d0+timedelta(days=i)).strftime(\"%Y.%-m.%-d.\")  # 2024.5.18. 형태\n",
        "            for i in range((d1-d0).days+1)]\n",
        "\n",
        "def gen_times():\n",
        "    return [f\"{h:02}:{m:02}\" for h in range(24) for m in range(60)]\n",
        "\n",
        "STOPWORDS += gen_dates() + gen_times()\n",
        "\n",
        "# 저장(선택)\n",
        "with open(SAVE_DIR/\"stopwords.pkl\", \"wb\") as fp:\n",
        "    pickle.dump(STOPWORDS, fp)\n",
        "\n",
        "# ▒▒ 3) FastText 모델 & 전처리 함수 ▒▒───────────────────────\n",
        "okt = Okt()\n",
        "ft  = fasttext.load_model(str(FT_MODEL))\n",
        "\n",
        "HASHTAG_RE = re.compile(r\"#\\S+\")\n",
        "\n",
        "def preprocess(text: str):\n",
        "    \"\"\"해시태그 제거+형태소 분리+불용어 제거+한글•영어 알파벳만 남김\"\"\"\n",
        "    text = HASHTAG_RE.sub(\"\", str(text)).strip()\n",
        "    toks = okt.morphs(text)\n",
        "    return [t for t in toks if t.isalpha() and t not in STOPWORDS]\n",
        "\n",
        "def sent2matrix(tokens):\n",
        "    \"\"\"토큰 리스트 → (PAD_LEN, EMB_DIM) 행렬\"\"\"\n",
        "    vecs = [ft.get_word_vector(tok) for tok in tokens]\n",
        "    if len(vecs) < PAD_LEN:\n",
        "        vecs += [np.zeros(EMB_DIM)] * (PAD_LEN - len(vecs))\n",
        "    else:\n",
        "        vecs = vecs[:PAD_LEN]\n",
        "    return np.array(vecs, dtype=np.float32)\n",
        "\n",
        "# 전체 문장 임베딩 캐싱 (→ 메모리 충분할 때)\n",
        "token_lists = []\n",
        "matrices = []\n",
        "for txt in tqdm(df[\"review\"], desc=\"Embedding\"):\n",
        "    toks = preprocess(txt)\n",
        "    token_lists.append(toks)\n",
        "    matrices.append(sent2matrix(toks))\n",
        "\n",
        "X = np.stack(matrices)               # (N, PAD_LEN, EMB_DIM)\n",
        "y = df[\"label\"].values.astype(np.float32)\n",
        "\n",
        "np.save(SAVE_DIR/\"embeddings.npy\", X)\n",
        "\n",
        "# ▒▒ 4) Dataset & DataLoader ▒▒──────────────────────────────\n",
        "class ReviewDS(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = torch.tensor(x)\n",
        "        self.y = torch.tensor(y)\n",
        "    def __len__(self):  return len(self.y)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]\n",
        "\n",
        "X_tr, X_te, y_tr, y_te, toks_tr, toks_te = train_test_split(\n",
        "    X, y, token_lists, test_size=0.2, stratify=y, random_state=SEED)\n",
        "\n",
        "tr_dl = DataLoader(ReviewDS(X_tr, y_tr), batch_size=BATCH_SIZE, shuffle=True)\n",
        "te_dl = DataLoader(ReviewDS(X_te, y_te), batch_size=1)\n",
        "\n",
        "# ▒▒ 5) LSTM+Self-Attention 모델 ▒▒──────────────────────────\n",
        "class LSTMAttn(nn.Module):\n",
        "    \"\"\"한 층 LSTM + 간단한 Self-Attention(weight sharing) + 이진 분류\"\"\"\n",
        "    def __init__(self, in_dim=EMB_DIM, hid=HIDDEN_DIM, seq_len=PAD_LEN):\n",
        "        super().__init__()\n",
        "        self.lstm   = nn.LSTM(in_dim, hid, batch_first=True)\n",
        "        self.w_attn = nn.Linear(seq_len, seq_len, bias=False)  # (B,h,seq)→(B,h,seq)\n",
        "        self.fc     = nn.Linear(hid*seq_len, 1)\n",
        "        self.flat   = nn.Flatten()\n",
        "\n",
        "    def forward(self, x):                     # x: (B,seq,in_dim)\n",
        "        h, _   = self.lstm(x)                 # (B,seq,hid)\n",
        "        p      = h.permute(0, 2, 1)           # (B,hid,seq)\n",
        "        q      = self.w_attn(p)               # (B,hid,seq)\n",
        "        attn   = h * q.permute(0, 2, 1)       # (B,seq,hid) element-wise\n",
        "        logit  = self.fc(self.flat(attn))     # (B,1)\n",
        "        return logit.squeeze(1), attn         # (B), (B,seq,hid)\n",
        "\n",
        "model     = LSTMAttn().to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "criterion  = nn.BCEWithLogitsLoss()\n",
        "optimizer  = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "def binarize(out):   # 로짓 → 0/1 tensor\n",
        "    return (torch.sigmoid(out) > .5).int()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68,
          "referenced_widgets": [
            "d79f7eb8e89540b587e65b54cd796184",
            "763ecae5c32348148a3251652d331309",
            "0067cafde56f4135a1fd9b4956f2aabb",
            "e539bf5546714878ad500292f078d569",
            "9fcafbcf7cd24a84b230b72a251dd359",
            "f9db2fee3c2c4c6182970a975eb9e59d",
            "673f745857e4498d85ed31b2654265a5",
            "0d0d67da7c5c4e148b1a24129c9aa4a5",
            "d60563109b3343d09cce94f1adef9ffe",
            "269832265c394a61baf23c4f6f58f82b",
            "a55d92e4312d4d0e8c31a7beb15386cd"
          ]
        },
        "id": "Wve7StplSWRa",
        "outputId": "b9003871-a1a2-47c2-f550-a7bdebb5123b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 샘플: 2080\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Embedding:   0%|          | 0/2080 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d79f7eb8e89540b587e65b54cd796184"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ▒▒ 6) 학습 루프  (LR Decay + Early Stopping) ▒▒──────────────────────\n",
        "BATCH_SIZE = 128        # (이미 선언돼 있으면 생략해도 무방)\n",
        "\n",
        "LR_PATIENCE  = 100      # validation loss가 개선되지 않을 때 LR 감소까지 기다릴 에포크 수\n",
        "ES_PATIENCE  = 150      # validation loss가 개선되지 않을 때 조기 종료까지 기다릴 에포크 수\n",
        "LR_FACTOR    = 0.1      # LR을 몇 배로 줄일지\n",
        "MIN_LR       = 1e-7     # 더 이상 줄이지 않을 최소 LR\n",
        "IMPROVE_DELTA = 1e-4    # loss 개선으로 인정할 최소 변화량\n",
        "\n",
        "best_loss          = float(\"inf\")\n",
        "lr_wait, es_wait   = 0, 0            # 두 개의 카운터\n",
        "device             = next(model.parameters()).device\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    # ─────────── Train ───────────\n",
        "    model.train()\n",
        "    train_loss, correct = 0.0, 0\n",
        "    for xb, yb in tr_dl:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        logit, _ = model(xb)\n",
        "        loss = criterion(logit, yb)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * len(yb)\n",
        "        correct    += (binarize(logit) == yb.int()).sum().item()\n",
        "\n",
        "    train_loss /= len(y_tr)\n",
        "    train_acc   = correct / len(y_tr)\n",
        "\n",
        "    # ─────────── Validation ───────\n",
        "    model.eval()\n",
        "    val_loss, correct = 0.0, 0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in te_dl:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            logit, _ = model(xb)\n",
        "            loss = criterion(logit, yb)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            correct  += (binarize(logit) == yb.int()).sum().item()\n",
        "\n",
        "    val_loss /= len(y_te)\n",
        "    val_acc   = correct / len(y_te)\n",
        "\n",
        "    # ─────────── 로그 출력 ────────\n",
        "    if epoch % 50 == 0 or epoch == 1:\n",
        "        print(f\"[{epoch:4d}/{EPOCHS}]  \"\n",
        "              f\"train:{train_loss:.4f}/{train_acc:.3f}  \"\n",
        "              f\"val:{val_loss:.4f}/{val_acc:.3f}\")\n",
        "\n",
        "    # ─────────── 개선 여부 판단 ────\n",
        "    if best_loss - val_loss > IMPROVE_DELTA:   # 충분히 개선\n",
        "        best_loss = val_loss\n",
        "        lr_wait   = 0\n",
        "        es_wait   = 0\n",
        "        torch.save(model.state_dict(), SAVE_DIR / \"best_model.pth\")\n",
        "    else:\n",
        "        lr_wait += 1\n",
        "        es_wait += 1\n",
        "\n",
        "    # ─────────── LR decay ──────────\n",
        "    if lr_wait >= LR_PATIENCE:\n",
        "        for group in optimizer.param_groups:\n",
        "            new_lr = max(group[\"lr\"] * LR_FACTOR, MIN_LR)\n",
        "            group[\"lr\"] = new_lr\n",
        "        lr_wait = 0\n",
        "        print(f\"→ LR decay, now {optimizer.param_groups[0]['lr']:.1e}\")\n",
        "\n",
        "    # ─────────── Early Stopping ────\n",
        "    if es_wait >= ES_PATIENCE:\n",
        "        print(f\"\\n◆ Early Stopping at epoch {epoch} (no val-loss improvement for {ES_PATIENCE} epochs)\")\n",
        "        break\n",
        "\n",
        "print(\"Best val loss:\", best_loss)\n",
        "\n",
        "# ▒▒ 7) 전체 데이터 성능 & F1 ▒▒──────────────────────────────\n",
        "model.load_state_dict(torch.load(SAVE_DIR / \"best_model.pth\"))\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    logits, attn = model(torch.tensor(X).to(device))\n",
        "pred = binarize(logits).cpu().numpy()\n",
        "f1   = f1_score(y, pred)\n",
        "acc  = accuracy_score(y, pred)\n",
        "print(f\"\\n전체 데이터 F1 = {f1:.4f}  ACC = {acc:.4f}\")\n",
        "\n",
        "# ▒▒ 9) 마무리 저장 ▒▒────────────────────────────────────────\n",
        "torch.save(model.state_dict(), SAVE_DIR / \"model_weights.pth\")\n",
        "print(\"\\n모델 가중치를\", SAVE_DIR / \"model_weights.pth\", \"에 저장 완료!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uY2QFZetURDE",
        "outputId": "4183eaf5-ecaf-4097-dc08-a16ec5c6d624"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   1/1000]  train:0.6878/0.797  val:0.6792/0.505\n",
            "[  50/1000]  train:0.0181/0.995  val:0.0252/0.995\n",
            "[ 100/1000]  train:0.0003/1.000  val:0.0422/0.995\n",
            "[ 150/1000]  train:0.0001/1.000  val:0.0538/0.995\n",
            "→ LR decay, now 1.0e-05\n",
            "[ 200/1000]  train:0.0000/1.000  val:0.0547/0.995\n",
            "\n",
            "◆ Early Stopping at epoch 201 (no val-loss improvement for 150 epochs)\n",
            "Best val loss: 0.02492677217445064\n",
            "\n",
            "전체 데이터 F1 = 0.9957  ACC = 0.9957\n",
            "\n",
            "모델 가중치를 /content/drive/MyDrive/25-1-Bridge/OUTPUT/model_weights.pth 에 저장 완료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WQOHC02BA8cI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ▒▒ 8) 어텐션이 집중된 단어 확인 ▒▒────────────────────────\n",
        "def top_tokens(att_mat, tokens, topk=5):\n",
        "    \"\"\"\n",
        "    att_mat : (seq_len, hidden) – 한 문장서 각 토큰의 attention(가중치) 행렬\n",
        "    tokens  : 해당 문장의 토큰 리스트\n",
        "    \"\"\"\n",
        "    scores = att_mat.sum(dim=1)                 # (seq_len,)\n",
        "    idxs   = torch.argsort(scores, descending=True)[:topk].tolist()\n",
        "    return [tokens[i] for i in idxs if i < len(tokens)]\n",
        "\n",
        "print(\"\\n📝 리뷰별 상위 Attention 단어\")\n",
        "for i in range(20):   # 앞 5문장만 예시\n",
        "    words = top_tokens(attn[i], token_lists[i])\n",
        "    label = \"광고\" if y[i] else \"일반\"\n",
        "    print(f\"{i:02d} ({label}) → {words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRNwm26abxac",
        "outputId": "72925d3e-f108-4e4c-ca4a-0e89e82186a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📝 리뷰별 상위 Attention 단어\n",
            "00 (광고) → ['정보', '장단점', '아고다', 'm', '수수료']\n",
            "01 (광고) → ['KTX', '약', '이동만', '워크샵', '내부']\n",
            "02 (광고) → ['둥지', '나이스', '원룸', '않는', '방']\n",
            "03 (광고) → ['제주', '제주', '조식', '제주', '먹고']\n",
            "04 (광고) → ['마켓', '쉐라톤', '투숙', '숙박', '날']\n",
            "05 (광고) → ['불편함은', '체험', '홍보', '여행', '굳이']\n",
            "06 (광고) → ['생활', 'LG', '제외', '반입', '음료']\n",
            "07 (광고) → ['천안', '갑자기', '쉴', '절정', '앱']\n",
            "08 (광고) → ['욕조', '어', '오히려', '목', '커서']\n",
            "09 (광고) → ['않는', '인근', '점', '건물', '주중']\n",
            "10 (광고) → ['센', '드린듯', '없으니', '차에', '여기는']\n",
            "11 (광고) → ['익산', '새로운', '지원', '비', '행복']\n",
            "12 (광고) → ['별도', '비발디', 'Ganglio', '홍천', '주방']\n",
            "13 (광고) → ['링크', '적용', '코드', '스테이', '목욕']\n",
            "14 (광고) → ['게임', '관광', '오픈', '수영', '가는']\n",
            "15 (광고) → ['체크', '뷰', '림', '뷰', '트윈']\n",
            "16 (광고) → ['라운지', '포함', '따로', '서울', '건물']\n",
            "17 (광고) → ['에이치', '핫', '플', '전주', '바']\n",
            "18 (광고) → ['건지', '대용', '주차', '담요', '그러세요']\n",
            "19 (광고) → ['현대', '결제', '해야', '선', '사람']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f18p8NQbB24n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─────────────────────────────────────────────────────────────\n",
        "# 셀 1: 저장된 최적 가중치 로드 후 validation(test) 성능 확인\n",
        "# ─────────────────────────────────────────────────────────────\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "VAL_BATCH = 32                           # 필요하면 조정\n",
        "weights_path = SAVE_DIR / \"best_model.pth\"\n",
        "\n",
        "# 1) 모델 초기화 & 가중치 로드\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model_val = LSTMAttn().to(device)\n",
        "model_val.load_state_dict(torch.load(weights_path, map_location=device))\n",
        "model_val.eval()\n",
        "\n",
        "# 2) Validation DataLoader\n",
        "val_dl = DataLoader(ReviewDS(X_te, y_te), batch_size=VAL_BATCH)\n",
        "\n",
        "# 3) 예측 & 지표 계산\n",
        "all_preds, all_trues = [], []\n",
        "with torch.no_grad():\n",
        "    for xb, yb in val_dl:\n",
        "        xb = xb.to(device)\n",
        "        logits, _ = model_val(xb)\n",
        "        preds = (torch.sigmoid(logits) > 0.5).cpu().int()\n",
        "        all_preds.append(preds)\n",
        "        all_trues.append(yb.int())\n",
        "all_preds = torch.cat(all_preds).numpy()\n",
        "all_trues = torch.cat(all_trues).numpy()\n",
        "\n",
        "f1  = f1_score(all_trues, all_preds)\n",
        "acc = accuracy_score(all_trues, all_preds)\n",
        "print(f\"[Validation] F1-score = {f1:.4f} | Accuracy = {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R552GPNiIGSn",
        "outputId": "fda2d2d1-4551-4c8f-9ab9-7e00d83a8eb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Validation] F1-score = 0.9952 | Accuracy = 0.9952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ─────────────────────────────────────────────────────────────\n",
        "# 셀 2: 전체 리뷰에 대해 광고일 확률(prob_ad) 계산하여 JSON에 추가\n",
        "# ─────────────────────────────────────────────────────────────\n",
        "FULL_BATCH = 256                        # GPU 메모리에 맞춰 조정\n",
        "\n",
        "# 1) DataLoader 구성\n",
        "full_dl = DataLoader(ReviewDS(X, y), batch_size=FULL_BATCH)\n",
        "\n",
        "# 2) 확률 예측\n",
        "probs = []\n",
        "model_val.eval()\n",
        "with torch.no_grad():\n",
        "    for xb, _ in full_dl:\n",
        "        xb = xb.to(device)\n",
        "        logits, _ = model_val(xb)\n",
        "        p = torch.sigmoid(logits).cpu().numpy()    # (B,)\n",
        "        probs.extend(p.tolist())\n",
        "\n",
        "# 3) 원본 DataFrame에 확률 열 추가 후 확인\n",
        "df_with_prob = df.copy()               # 기존 df: review / label\n",
        "df_with_prob[\"prob_ad\"] = probs        # ad(1)일 확률\n",
        "\n",
        "print(df_with_prob.head())\n",
        "\n",
        "# (선택) JSON으로 저장하려면:\n",
        "output_json_path = SAVE_DIR / \"reviews_with_prob.json\"\n",
        "df_with_prob.to_json(output_json_path, orient=\"records\", force_ascii=False, indent=2)\n",
        "print(f\"\\n✓ 확률 추가 JSON 저장: {output_json_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DO-mB4dIG9M",
        "outputId": "7e79a859-b3cb-48bf-caef-0261a21a2c64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review  label  prob_ad\n",
            "0  더 좋은 여행 정보를 제공하기 위해 \\n아고다와 함께 합니다.\\n본 콘텐츠를 통한 ...      1      1.0\n",
            "1  며칠 전 여수로 IP 워크샵을 다녀왔다.\\n당일 오후 2시 워크샵 시작이라 오전 시...      1      1.0\n",
            "2  주의\\n이 글은 더이상 작성하지 않는 글입니다. 차후 삭제 될수 있습니다.\\n[이전...      1      1.0\n",
            "3  제주 웰니스 WE호텔\\n다양한 힐링 프로그램이 있는 웰니스 WE호텔\\nWE호텔\\n제...      1      1.0\n",
            "4  방콕여행 3일차 : 페닌슐라 방콕 조식뷔페 - 방콕 쉐라톤 그랜드 수쿰빗 숙박 후기...      1      1.0\n",
            "\n",
            "✓ 확률 추가 JSON 저장: /content/drive/MyDrive/25-1-Bridge/OUTPUT/reviews_with_prob.json\n"
          ]
        }
      ]
    }
  ]
}