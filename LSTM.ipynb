{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d79f7eb8e89540b587e65b54cd796184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_763ecae5c32348148a3251652d331309",
              "IPY_MODEL_0067cafde56f4135a1fd9b4956f2aabb",
              "IPY_MODEL_e539bf5546714878ad500292f078d569"
            ],
            "layout": "IPY_MODEL_9fcafbcf7cd24a84b230b72a251dd359"
          }
        },
        "763ecae5c32348148a3251652d331309": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9db2fee3c2c4c6182970a975eb9e59d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_673f745857e4498d85ed31b2654265a5",
            "value": "Embedding:â€‡100%"
          }
        },
        "0067cafde56f4135a1fd9b4956f2aabb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d0d67da7c5c4e148b1a24129c9aa4a5",
            "max": 2080,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d60563109b3343d09cce94f1adef9ffe",
            "value": 2080
          }
        },
        "e539bf5546714878ad500292f078d569": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_269832265c394a61baf23c4f6f58f82b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a55d92e4312d4d0e8c31a7beb15386cd",
            "value": "â€‡2080/2080â€‡[02:22&lt;00:00,â€‡41.85it/s]"
          }
        },
        "9fcafbcf7cd24a84b230b72a251dd359": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9db2fee3c2c4c6182970a975eb9e59d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "673f745857e4498d85ed31b2654265a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d0d67da7c5c4e148b1a24129c9aa4a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d60563109b3343d09cce94f1adef9ffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "269832265c394a61baf23c4f6f58f82b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a55d92e4312d4d0e8c31a7beb15386cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bst56GU78w8G",
        "outputId": "f8a1c937-a034-4517-f6e3-2d35e0d13b36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tGPk8-T7SxhG",
        "outputId": "10f44ee8-7433-451e-fa4c-0e79c4d64fa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/73.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fasttext) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fasttext) (2.0.2)\n",
            "Collecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading jpype1-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from konlpy) (5.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from JPype1>=0.7.0->konlpy) (24.2)\n",
            "Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jpype1-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (494 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m494.1/494.1 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.3-cp311-cp311-linux_x86_64.whl size=4313503 sha256=be9ccd5c2219019cdac7001e5f5fcaf3eceae6dce97aa3907178a0ede16488e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/4f/35/5057db0249224e9ab55a513fa6b79451473ceb7713017823c3\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, JPype1, konlpy, fasttext\n",
            "Successfully installed JPype1-1.5.2 fasttext-0.9.3 konlpy-0.6.0 pybind11-2.13.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â–’â–’ 0) í™˜ê²½ ì„¤ì • â–’â–’â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "import os, json, re, pickle, random\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import fasttext\n",
        "from konlpy.tag import Okt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "\n",
        "# ì‘ì—… ê²½ë¡œë“¤ (í•„ìš”í•˜ë©´ ìˆ˜ì •)\n",
        "DATA_PATH   = Path(\"/content/drive/MyDrive/25-1-Bridge/combined_labeled_reviews.json\")   # â† ìƒˆ JSON\n",
        "FT_MODEL    = Path(\"/content/drive/MyDrive/25-1-Bridge/cc.ko.300.bin\")\n",
        "SAVE_DIR    = Path(\"/content/drive/MyDrive/25-1-Bridge/OUTPUT\"); SAVE_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# í•™ìŠµ í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
        "BATCH_SIZE      = 128\n",
        "PAD_LEN         = 800      # ë¬¸ì¥ ë‹¹ ë‹¨ì–´ ë²¡í„° ìˆ˜\n",
        "EMB_DIM         = 300\n",
        "HIDDEN_DIM      = 32\n",
        "EPOCHS          = 1000\n",
        "PATIENCE        = 100      # early lr-decay\n",
        "LR              = 1e-4\n",
        "\n",
        "# â–’â–’ 1) ë°ì´í„° ë¡œë“œ â–’â–’â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def load_json(path: Path):\n",
        "    \"\"\"ìƒˆ í¬ë§·: [{\"review\": \"...\", \"label\": \"ad\"|\"non_ad\"}, ...]\"\"\"\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as fp:\n",
        "        data = json.load(fp)\n",
        "    df = pd.DataFrame(data)\n",
        "    # label ë§¤í•‘: ad â†’1, non_ad â†’0\n",
        "    df[\"label\"] = df[\"label\"].map({\"ad\": 1, \"non_ad\": 0})\n",
        "    return df\n",
        "\n",
        "df = load_json(DATA_PATH)\n",
        "print(\"ì´ ìƒ˜í”Œ:\", len(df))\n",
        "\n",
        "# â–’â–’ 2) ë¶ˆìš©ì–´ ì‚¬ì „ êµ¬ì¶• â–’â–’â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 2-1) ì‚¬ìš©ì ìˆ˜ë™ ë¦¬ìŠ¤íŠ¸\n",
        "STOPWORDS = ['ì´', 'ê·¸', 'ì €', 'ì€', 'ëŠ”', 'ì´ì—ˆ', 'í•©ë‹ˆë‹¤', 'ê·¸ë¦¬ê³ ', 'í•˜ì§€ë§Œ', 'ì„', 'ë¥¼', 'ì—', 'ì˜', 'ê°€',\n",
        "             '~', ':)', '!', ')', '(', '.', ',', 'ìª½ì§€', 'ê³µê°', 'ìŠ¤í¬ë©', 'ìµëª…', '(?)', '?', '!', '~~',\n",
        "             'í›„ê¸°', 'ì—°ì„¸ëŒ€', 'ì„œë¬¸', 'ì‹ ê³ ', 'ãƒ»', 'URL', 'ë³µì‚¬', 'ì„ íƒ', 'ì¶”ì²œ', 'ë„¤ì´ë²„', 'ë¦¬ë·°', 'ì‹ë‹¹',\n",
        "             'ìŒì‹', 'ë‘', 'ì™€', 'ìœ¼ë¡œ', 'ìœ¼ë¡œëŠ”', '-', 'ì´ë‘', 'ì•¼', 'ì˜†', 'ê¹Œì§€', 'ê»˜ì„œ', 'ë„', 'ì•', 'ì§€ë§Œ',\n",
        "             'ê·¸ëŸ°ë°', 'ì‚¬ì‹¤', 'ì´ë¼', 'ë‚´', \"'\", 'ë‹¤ë§Œ', ':', '..', 'ë³´ë‹¤', 'ë„ˆë¬´', 'ë”', 'ì§„ì§œ', 'ê°œ', 'ê³¼',\n",
        "             'ì¢€', 'ë“¤', 'í•œ', 'ë‹˜', 'í•˜ê³ ', 'ë“ ', 'ì „', 'ê³„ì†', 'ì¸ë°', 'ì´ë¼ëŠ”', 'ë²•', '+', 'ìª½', 'ìŒ', 'ì•„',\n",
        "             'ì •ë„', 'ì›', 'ë§µ', 'ëª»', 'ì´ì—ˆê³ ', 'ê½¤', 'ì´', 'í‰', 'ì´ê³ ', 'ë¶„', 'ì„¸', 'ì¡°ê¸ˆ', 'ë³´ë‹ˆ', 'ìœ¼ë¡œì„œ',\n",
        "             'ì•„ë˜', 'ì¯¤', 'ë³¸ë¬¸', 'ì¶”ê°€', 'ì´ì›ƒ', 'ì—¬ê¸°', 'ì£¼ìœ„', 'ê·¹', 'ëŒ€', 'ë…¸', 'ëŒ€ë°•', 'ëª¨', 'ê²ƒ', 'ë°–ì—',\n",
        "             'ê·¸ëƒ¥', 'ì—ì„œë„', 'í• ', 'ê·¼ëŒ€', 'ê°™ì´', 'ì²˜ëŸ¼', 'ì‹ ì´Œ', 'ê³ ì„œ', 'í‰ì†Œ', 'ë„¤', 'ë²ˆì§¸', 'ë³„ë¡œ', 'ìˆ˜ë„',\n",
        "             'ìš°ë¦¬', 'ë¡œ', 'ì•ˆ', 'ê¸€', 'ê±°', 'ë‚˜', 'ì§‘', 'ë‹¤', 'ã…ã…', 'ã…', 'ã…‹', 'ì§œë¦¬', 'ê¸°íƒ€', 'ë¼ì„œ', 'ëŠë‚Œ',\n",
        "             'ì ', 'ë³¸', 'ã…‹ã…‹', 'ë°©ë¬¸', 'ë´ì„œ', 'ìƒí™©', 'í•œë²ˆ', 'ì—ì„œ', 'í•´ìš”', 'ìš”', 'ì˜¤', 'ë‚´ëˆë‚´ì‚°', 'ì†”ì§í›„ê¸°',\n",
        "             'ì œê³µ', 'ê´‘ê³ ì„±', 'ê´‘ê³ ', '2024', '2023', '2022', 'ì‹œê°„', 'ë¶„', 'ì „', 'AM', 'PM', 'am', 'pm',\n",
        "             'ì´ìš©', 'ìœ„ì¹˜', 'ë§›ì§‘', 'ì‹œê°„', 'ì£¼ë¬¸', 'ë©”ë‰´', 'ì˜ˆì•½', 'ì˜ì—…',\n",
        "             'ë§›', 'ê·¼ì²˜', 'ì†Œê°œ', 'ì‚¬ì§„', 'ìœ„í•´', 'ì—¬ê¸°', 'ì—ì„œëŠ”', 'ì—ì„œ',\n",
        "             'ê³³', 'ë‹¤ë…€ì™”ì–´ìš”', 'ë¨¹ì—ˆì–´ìš”', 'ê°”ìŠµë‹ˆë‹¤', 'í•©ë‹ˆë‹¤', 'ì…ë‹ˆë‹¤',\n",
        "             'í–ˆìŠµë‹ˆë‹¤', 'ë‹¤ìŒ', 'ëˆ„êµ¬', 'íŠ¹íˆ', 'ë•Œ', 'ìˆëŠ”', 'ë§¤ì¼',\n",
        "             'ê°€ëŠ¥', 'ì¶”ì²œ', 'ê²€ìƒ‰', 'ì˜', 'ë‹¤', 'ëœ', 'ì¤‘', 'ì™€ì„œ',\n",
        "             'ë§›ìˆëŠ”', 'ìˆ˜', 'ê³³', 'ìˆëŠ”', 'í•´ì„œ', 'ì§ì ‘', 'ìƒˆë¡œ',\n",
        "             'í•˜ê³ ', 'í•˜ì‹œ', 'ì €ë…', 'ì ì‹¬', 'ì•„ì¹¨',\n",
        "             'ê°€ëŠ¥í•œ', 'ì •ë§', 'ë§ì€', 'ëª¨ë‘', 'ë³´ë‹¤ëŠ”',  'í•˜ëŠ”',\n",
        "             'í•´ì£¼ì‹œëŠ”', 'íœ´ë¬´', 'ë§¤ì£¼', 'í•„ìš”', 'ì¢‹ì•„ìš”', 'ë§ì•„ì„œ', 'ë‹¤ë…€ì˜¤ê³ ',\n",
        "             'ê²Œ', 'ëŠ”', 'ì„', 'ë¥¼', 'ì´', 'ê°€', 'ì˜', 'ì—', 'ì™€', 'ê³¼',\n",
        "             'ë¡œ', 'ìœ¼ë¡œ', 'ë„', 'ë‹¤', 'ë§Œ', 'ë³´ë‹¤', 'ë¶€í„°', 'ê·¸ë¦¬ê³ ',\n",
        "             'ë˜ëŠ”', 'í•´ì„œ', 'ì¸ë°', 'ì´ë¼', 'ì´ë©°', 'ë˜', 'ê·¸', 'í•˜ì§€ë§Œ',\n",
        "             'ê·¸ë˜ë„', 'ë•Œë¬¸ì—', 'ì´ëŸ°', 'ì €ëŸ°', 'ê·¸ëŸ°', 'ë”', 'ê¹Œì§€',\n",
        "             'í•˜ë©´', 'ë“ ', 'ìš”', 'í•˜ë‹ˆ', 'í•˜ë©´ì„œ', 'ìœ¼ë¡œì¨', 'ì¤‘ì—', 'ì²˜ëŸ¼','ì“°ê³ ìˆë‹¤ê³ ','ë•Œë¬¸',\n",
        "             'ê°ˆ','ìˆì–´ìš”','ì´ì—ˆëŠ”ë°','ì—ëŠ”','ë§ˆë‹¤','ì—†ì´','í–ˆì–´ìš”','ìˆì—ˆì–´ìš”','ë¬','ì ê³ ',\n",
        "             'ìˆì—ˆê¸°','í–ˆëŠ”ì§€','ì°¸','ìˆê³ ','ìˆë„ë¡','ë˜ì–´','ë¼ê³ ','ì¢‹ì•˜ìš”','ë‹ˆë‹¹','ì–´ë–¤','ë¦¬ê¸°',\n",
        "             'ìˆì—ˆë˜','ë¦¬ë„','ì‡','í•˜ê¸¸ë˜','ìˆë‹¤','ì¼ê¹Œ','ì§€','ë˜ëŠ”','ì•„ë‹Œ','ê³ ','D','ë“±','í†µí•´',\n",
        "             'ë°','ê²¸','ì•Šê³ ','S','ì´ë‚˜','ë¬´ì—‡','ë˜í•œ','ë“œë¦½ë‹ˆë‹¤','A','í•˜ê² ìŠµë‹ˆë‹¤','ë³´ë©´','ê·¸ë ‡ë‹¤ë©´',\n",
        "             'ìˆì–´ì„œ','í•™','ë¼','ì§‘ë‹ˆë‹¤','ë©´','ì—ëŠ”','T','X','ë‹ˆ','í•˜ëŠ”ë°ìš”','ì—ê²Œ','ì´ì—ˆë„¤ìš”','ë“¯',\n",
        "             'ìˆ','o','set','ê°™ì•„ìš©','ìì•„ë‚´ì£ ','ê±´','Instagram','ëŒ€í•´','ì´ê±´','ì´ì—ˆìŠµë‹ˆë‹¤',\n",
        "             'Rachadamnoen','ë³´ì´ëŠ”','ê°ì¢…','ì´ì„œ','ì˜€ë‹¤','ìˆì—ˆìŠµë‹ˆë‹¤','ì‹¶ì€','ë˜ì–´ìˆì–´ì„œ',\n",
        "             'í•˜ì‹­ë‹ˆë‹¤','ì˜€ì–´ìš”','ã…‹ã…‹ã…‹','ì±„','OO','ã…¡','ê·¸ë ‡ê²Œ','ì´ì„œ','ê±´ê°€','ì•—','ì˜€ì–´ìš”','ì €í¬',\n",
        "             'í–ˆì„','ë“¬ë¿','ë„˜','ë‹¨ì²´','ê°™ë„¤ìš”','ë©”ë‰´','êµ­ë¬¼', 'ë„ì‚­ë©´', 'ë°±ê¹€ì¹˜', 'ë–¡ê°ˆë¹„', 'íŒŸíƒ€ì´',\n",
        "             'ì˜¹ì‹¬ì´', 'ê²Œì¥', 'ê³„ë€ë§ì´', 'ì–´ë¬µ', 'ë°˜ì°¬', 'ë§Œë‘', 'í•œìš°', 'ìœ¡ì „','íŠ€ê¹€', 'ì´ˆë°¥', 'êµ­ë¬¼', 'ë‹­ë°œ', 'ëª©ì‚´', 'ì¹˜í‚¨',\n",
        "             'ê¼¬ì¹˜', 'ë¹„ë¹”êµ­ìˆ˜', 'ë“¤ê¹¨', 'ê¹€ë°¥', 'í•´ì¥êµ­', 'ë°˜ì°¬', 'ìŒˆë¬´', 'ëˆê¹ŒìŠ¤','ë‹­ë°œ', 'ì¹˜í‚¨', 'ë“¤ê¹¨', 'ì¥íƒ•', 'ìƒˆìš°',\n",
        "             'êµ­ìˆ˜', 'ì¹´ì¸ ','ê¹€ë°¥', 'ê°ˆë¹„', 'ê¹€ì¹˜', 'ëƒ‰ë©´','ì¸ê°€ìš”','ëìŠµë‹ˆë‹¤','ë˜ì—ˆë”ë¼êµ¬ìš”','Mueang','ê·¸ë§Œ','ì¹˜ê³ ëŠ”',\n",
        "             'ìˆëƒë©´','ì¸','ë˜ì–´ìˆì—ˆë‹¤','íŒ…','ì”©',' ','ë²„ê±°','ì°','ì´ë ‡ê²Œ','ì™','ì œ','ì´ë„¤ìš”','ë°','í•´ë„','ì–´ëŠ','ë¡œì„œ','ã„¹','ë†€',\n",
        "             'ë­”','í•˜ì§€','ì‡ë‹¤ê³ ','ì˜€ë˜','ë”°ë¼','í•©ë‹ˆë‹¹','ë¶€íƒë“œë¦½ë‹ˆë‹¹','ì´ì œ','ë”','ê¼­','ì—ë„','í•œë‹¤ëŠ”','í•˜','ìˆìŠµë‹ˆë‹¤','ìŠ¤ëŸ½ê²Œ',\n",
        "             'ë“œë¦¼ë‹¤','í•˜ì‹ ë‹¤ë©´','ì—”','ì—ë„','ê¼­','ìµœê³ ','ì¢‹ì€','ê°™ì•„ìš”','ì•„ë§ˆ','ã… ã… ','ë°”ë¡œ','','ì˜¤ëŠ˜','ë”±','í•¨ê»˜','ì´ì§€ë§Œ',\n",
        "             'ì™¸','ì”©','ERang','naver','ë¿','NO','nail','go','ã…ã…ã…','ìœ„','ì¸','ê»','ëœ¨','ì†','ë´…ë‹ˆë‹¤','í¬','ë”ìš±','ë ¤ê³ ',\n",
        "             'ì—„ì²­','ì¢‹ì€','í–ˆë˜','ìˆê²Œ','ë˜ì„œ','í•œë°','ìˆëŠ”ë°','ë‚´ë‚´','ì˜ˆìš”','ì´ë‹ˆê¹Œ','ì´ë‹¤','ì—­ì‹œ','êµ¿','ì¸µ','ìš°ì‚¼ê²¹',\n",
        "             'ì›€','ë•ë¶„','ê·¸ëŸ¼ì—ë„','g','ì´ì—ˆë‹¤','ì¼ë‹¨','ìš”ì¦˜','ê³„ë€ì°œ','ê°€ì¥','ì§ ','í•˜ë‹¤','ì´ë¼ê³ ','í–ˆë‹¤','ì¦ˆ','ì•„ì£¼',\n",
        "             'ìì£¼','ëª¨ë“ ','ë˜ì—ˆìŠµë‹ˆë‹¤','ê³µìœ ','ëŒ“ê¸€','í˜¹ì‹œ','ê°ˆì¹˜','êµ¬ì´','ã… ','ìƒ¤ë¸Œìƒ¤ë¸Œ','ì†Œë°˜','ì´ì—ìš”','middot','ë¼ëŠ”',\n",
        "             'ì›€','ë‹­ê°ˆë¹„','ìŒˆ','ê±°ì•¼','ìµíˆ','ê°™ì•˜ì–´ìš”','ë¼ê³¤','í•œí…Œ','ê±¸','ì´ì—ˆë˜','ì„œ','3','ê±¸','í–ˆëŠ”ë°ìš”','ì‹¶ë„¤ìš”','ê¹Œìš”',\n",
        "             'íŒŒìŠ¤íƒ€','ìˆë‹¤ë©´','ìˆë‹¤ê³ ','ìµíˆ','ë¼ê³¤','ì´ì—ˆë˜','ë¼ë©´','ë©ë©','ìœ¼ë¡œë„','í–ˆì—ˆë˜','ê·¸ë˜ì„œ','ê³ ê³ ','ë™ì•ˆ',\n",
        "             'o','ê¿”','ì²œ','ì•„ë‹ˆë¼','ë§¤ìš°','ë‹¤ë…€ì˜¤ì‹¤ìˆ˜ìˆì–´ìš©','ì—ê¹Œì§€','ì„œ','ë‹ˆê¹Œ','ì¸ì§€','ìˆìœ¼ë©°','ì£ ','K','ë¼ë©´','ë¬¼ë¡ ',\n",
        "             'OGQ','me','thumb','ë‚˜ì•¼','ê² ì£ ','ë‘','ë‚œ','ì—ê²ŒëŠ”','ì ¤ë£¨','K','í•˜êµ¬ìš”','ë©´ì„œ','í•˜ëŠ”ë°','ë ','í•˜ê¸°ì—','ê»„',\n",
        "             'ã…‹ã…‹ã…‹ã…‹ã…‹','ë­','d','you','Chang','ê°€ì¸ ë®ë°¥','ì¿ ì‹œì¹´ì¸ ','ë¯¸ì—­êµ­','ì­ˆêµ¬ë¯¸','ê°ˆë¹„íƒ•','í‰ì¼','ë¶€íƒ€ë™','ë©”ë¡ ë¹µ',\n",
        "             'ê»í•­ì •','ê·¸ë¦¬','ê±°ê¸°','mp','ë§‰êµ­ìˆ˜','ëˆê¹ŒìŠ¤','ì¹˜ì¦ˆìŠ¤í‹±','ëª¨ë“¬ì „','ã…‹ã…‹ã…‹ã…‹','áµ”','ê°™ì€','ì—ìš”','ì—¬','ê°','ë¼ë©˜',\n",
        "             'ë‹¤ë¥¸','ë³´í†µ','ê°‘ë‹ˆë‹¹','ê³±ì°½','ì—°ì–´','ì´ì—ˆì–´ìš”','ìˆ˜ìœ¡','ê¹€ì¹˜ì°Œê°œ','í•œë‹¤ë©´','í•˜ë£¨í•˜ë£¨','ã… ã… ã… ','    ','ì¥ì–´','ë¼ì§€êµ­ë°¥',\n",
        "             'ëŒ€ë¡œ','ìœ¼','ì™„ì „','ì˜¤í›„','ë¬´ë µ','ë„‰','êµ¬','ì—ì„œë§Œ','ì‹œ','í–„ë²„ê±°','í”¼ì','ì­ˆê¾¸ë¯¸', \"í˜¸í…”\", \"ê°ì‹¤\", \"êµí†µ\", \"ì‹œì„¤\",\n",
        "             \"ì˜¤ì†¡\", \"ê°•ë‚¨\", \"ë‚¨ì›\", \"ì„œê·€í¬ì‹œ\", \"ì¥ì†Œ\", \"í„°ë¯¸ë„\", \"ìˆ˜ì¿°ë¹—\", \"í•˜ì¹´íƒ€ì—­\", \"ë§ˆì¹´ì˜¤\", \"ë””ëŸ­ìŠ¤\", \"ë¥´\", \"í™ëŒ€\"\n",
        "             ]\n",
        "\n",
        "# 2-2) ëª¨ë“  ë‚ ì§œÂ·ì‹œê° ë¬¸ìì—´ì„ ë¶ˆìš©ì–´ì— ì¶”ê°€\n",
        "def gen_dates(start=2022, end=2024):\n",
        "    d0, d1 = datetime(start,1,1), datetime(end,12,31)\n",
        "    return [(d0+timedelta(days=i)).strftime(\"%Y.%-m.%-d.\")  # 2024.5.18. í˜•íƒœ\n",
        "            for i in range((d1-d0).days+1)]\n",
        "\n",
        "def gen_times():\n",
        "    return [f\"{h:02}:{m:02}\" for h in range(24) for m in range(60)]\n",
        "\n",
        "STOPWORDS += gen_dates() + gen_times()\n",
        "\n",
        "# ì €ì¥(ì„ íƒ)\n",
        "with open(SAVE_DIR/\"stopwords.pkl\", \"wb\") as fp:\n",
        "    pickle.dump(STOPWORDS, fp)\n",
        "\n",
        "# â–’â–’ 3) FastText ëª¨ë¸ & ì „ì²˜ë¦¬ í•¨ìˆ˜ â–’â–’â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "okt = Okt()\n",
        "ft  = fasttext.load_model(str(FT_MODEL))\n",
        "\n",
        "HASHTAG_RE = re.compile(r\"#\\S+\")\n",
        "\n",
        "def preprocess(text: str):\n",
        "    \"\"\"í•´ì‹œíƒœê·¸ ì œê±°+í˜•íƒœì†Œ ë¶„ë¦¬+ë¶ˆìš©ì–´ ì œê±°+í•œê¸€â€¢ì˜ì–´ ì•ŒíŒŒë²³ë§Œ ë‚¨ê¹€\"\"\"\n",
        "    text = HASHTAG_RE.sub(\"\", str(text)).strip()\n",
        "    toks = okt.morphs(text)\n",
        "    return [t for t in toks if t.isalpha() and t not in STOPWORDS]\n",
        "\n",
        "def sent2matrix(tokens):\n",
        "    \"\"\"í† í° ë¦¬ìŠ¤íŠ¸ â†’ (PAD_LEN, EMB_DIM) í–‰ë ¬\"\"\"\n",
        "    vecs = [ft.get_word_vector(tok) for tok in tokens]\n",
        "    if len(vecs) < PAD_LEN:\n",
        "        vecs += [np.zeros(EMB_DIM)] * (PAD_LEN - len(vecs))\n",
        "    else:\n",
        "        vecs = vecs[:PAD_LEN]\n",
        "    return np.array(vecs, dtype=np.float32)\n",
        "\n",
        "# ì „ì²´ ë¬¸ì¥ ì„ë² ë”© ìºì‹± (â†’ ë©”ëª¨ë¦¬ ì¶©ë¶„í•  ë•Œ)\n",
        "token_lists = []\n",
        "matrices = []\n",
        "for txt in tqdm(df[\"review\"], desc=\"Embedding\"):\n",
        "    toks = preprocess(txt)\n",
        "    token_lists.append(toks)\n",
        "    matrices.append(sent2matrix(toks))\n",
        "\n",
        "X = np.stack(matrices)               # (N, PAD_LEN, EMB_DIM)\n",
        "y = df[\"label\"].values.astype(np.float32)\n",
        "\n",
        "np.save(SAVE_DIR/\"embeddings.npy\", X)\n",
        "\n",
        "# â–’â–’ 4) Dataset & DataLoader â–’â–’â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "class ReviewDS(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = torch.tensor(x)\n",
        "        self.y = torch.tensor(y)\n",
        "    def __len__(self):  return len(self.y)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]\n",
        "\n",
        "X_tr, X_te, y_tr, y_te, toks_tr, toks_te = train_test_split(\n",
        "    X, y, token_lists, test_size=0.2, stratify=y, random_state=SEED)\n",
        "\n",
        "tr_dl = DataLoader(ReviewDS(X_tr, y_tr), batch_size=BATCH_SIZE, shuffle=True)\n",
        "te_dl = DataLoader(ReviewDS(X_te, y_te), batch_size=1)\n",
        "\n",
        "# â–’â–’ 5) LSTM+Self-Attention ëª¨ë¸ â–’â–’â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "class LSTMAttn(nn.Module):\n",
        "    \"\"\"í•œ ì¸µ LSTM + ê°„ë‹¨í•œ Self-Attention(weight sharing) + ì´ì§„ ë¶„ë¥˜\"\"\"\n",
        "    def __init__(self, in_dim=EMB_DIM, hid=HIDDEN_DIM, seq_len=PAD_LEN):\n",
        "        super().__init__()\n",
        "        self.lstm   = nn.LSTM(in_dim, hid, batch_first=True)\n",
        "        self.w_attn = nn.Linear(seq_len, seq_len, bias=False)  # (B,h,seq)â†’(B,h,seq)\n",
        "        self.fc     = nn.Linear(hid*seq_len, 1)\n",
        "        self.flat   = nn.Flatten()\n",
        "\n",
        "    def forward(self, x):                     # x: (B,seq,in_dim)\n",
        "        h, _   = self.lstm(x)                 # (B,seq,hid)\n",
        "        p      = h.permute(0, 2, 1)           # (B,hid,seq)\n",
        "        q      = self.w_attn(p)               # (B,hid,seq)\n",
        "        attn   = h * q.permute(0, 2, 1)       # (B,seq,hid) element-wise\n",
        "        logit  = self.fc(self.flat(attn))     # (B,1)\n",
        "        return logit.squeeze(1), attn         # (B), (B,seq,hid)\n",
        "\n",
        "model     = LSTMAttn().to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "criterion  = nn.BCEWithLogitsLoss()\n",
        "optimizer  = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "def binarize(out):   # ë¡œì§“ â†’ 0/1 tensor\n",
        "    return (torch.sigmoid(out) > .5).int()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68,
          "referenced_widgets": [
            "d79f7eb8e89540b587e65b54cd796184",
            "763ecae5c32348148a3251652d331309",
            "0067cafde56f4135a1fd9b4956f2aabb",
            "e539bf5546714878ad500292f078d569",
            "9fcafbcf7cd24a84b230b72a251dd359",
            "f9db2fee3c2c4c6182970a975eb9e59d",
            "673f745857e4498d85ed31b2654265a5",
            "0d0d67da7c5c4e148b1a24129c9aa4a5",
            "d60563109b3343d09cce94f1adef9ffe",
            "269832265c394a61baf23c4f6f58f82b",
            "a55d92e4312d4d0e8c31a7beb15386cd"
          ]
        },
        "id": "Wve7StplSWRa",
        "outputId": "b9003871-a1a2-47c2-f550-a7bdebb5123b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì´ ìƒ˜í”Œ: 2080\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Embedding:   0%|          | 0/2080 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d79f7eb8e89540b587e65b54cd796184"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â–’â–’ 6) í•™ìŠµ ë£¨í”„  (LRâ€†Decay + Early Stopping) â–’â–’â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "BATCH_SIZE = 128        # (ì´ë¯¸ ì„ ì–¸ë¼ ìˆìœ¼ë©´ ìƒëµí•´ë„ ë¬´ë°©)\n",
        "\n",
        "LR_PATIENCE  = 100      # validation lossê°€ ê°œì„ ë˜ì§€ ì•Šì„ ë•Œ LR ê°ì†Œê¹Œì§€ ê¸°ë‹¤ë¦´ ì—í¬í¬ ìˆ˜\n",
        "ES_PATIENCE  = 150      # validation lossê°€ ê°œì„ ë˜ì§€ ì•Šì„ ë•Œ ì¡°ê¸° ì¢…ë£Œê¹Œì§€ ê¸°ë‹¤ë¦´ ì—í¬í¬ ìˆ˜\n",
        "LR_FACTOR    = 0.1      # LRì„ ëª‡ ë°°ë¡œ ì¤„ì¼ì§€\n",
        "MIN_LR       = 1e-7     # ë” ì´ìƒ ì¤„ì´ì§€ ì•Šì„ ìµœì†Œ LR\n",
        "IMPROVE_DELTA = 1e-4    # loss ê°œì„ ìœ¼ë¡œ ì¸ì •í•  ìµœì†Œ ë³€í™”ëŸ‰\n",
        "\n",
        "best_loss          = float(\"inf\")\n",
        "lr_wait, es_wait   = 0, 0            # ë‘ ê°œì˜ ì¹´ìš´í„°\n",
        "device             = next(model.parameters()).device\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Train â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    model.train()\n",
        "    train_loss, correct = 0.0, 0\n",
        "    for xb, yb in tr_dl:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        logit, _ = model(xb)\n",
        "        loss = criterion(logit, yb)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * len(yb)\n",
        "        correct    += (binarize(logit) == yb.int()).sum().item()\n",
        "\n",
        "    train_loss /= len(y_tr)\n",
        "    train_acc   = correct / len(y_tr)\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Validation â”€â”€â”€â”€â”€â”€â”€\n",
        "    model.eval()\n",
        "    val_loss, correct = 0.0, 0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in te_dl:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            logit, _ = model(xb)\n",
        "            loss = criterion(logit, yb)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            correct  += (binarize(logit) == yb.int()).sum().item()\n",
        "\n",
        "    val_loss /= len(y_te)\n",
        "    val_acc   = correct / len(y_te)\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë¡œê·¸ ì¶œë ¥ â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    if epoch % 50 == 0 or epoch == 1:\n",
        "        print(f\"[{epoch:4d}/{EPOCHS}]  \"\n",
        "              f\"train:{train_loss:.4f}/{train_acc:.3f}  \"\n",
        "              f\"val:{val_loss:.4f}/{val_acc:.3f}\")\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê°œì„  ì—¬ë¶€ íŒë‹¨ â”€â”€â”€â”€\n",
        "    if best_loss - val_loss > IMPROVE_DELTA:   # ì¶©ë¶„íˆ ê°œì„ \n",
        "        best_loss = val_loss\n",
        "        lr_wait   = 0\n",
        "        es_wait   = 0\n",
        "        torch.save(model.state_dict(), SAVE_DIR / \"best_model.pth\")\n",
        "    else:\n",
        "        lr_wait += 1\n",
        "        es_wait += 1\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ LR decay â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    if lr_wait >= LR_PATIENCE:\n",
        "        for group in optimizer.param_groups:\n",
        "            new_lr = max(group[\"lr\"] * LR_FACTOR, MIN_LR)\n",
        "            group[\"lr\"] = new_lr\n",
        "        lr_wait = 0\n",
        "        print(f\"â†’ LR decay, now {optimizer.param_groups[0]['lr']:.1e}\")\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Early Stopping â”€â”€â”€â”€\n",
        "    if es_wait >= ES_PATIENCE:\n",
        "        print(f\"\\nâ—† Early Stopping at epoch {epoch} (no val-loss improvement for {ES_PATIENCE} epochs)\")\n",
        "        break\n",
        "\n",
        "print(\"Best val loss:\", best_loss)\n",
        "\n",
        "# â–’â–’ 7) ì „ì²´ ë°ì´í„° ì„±ëŠ¥ & F1 â–’â–’â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "model.load_state_dict(torch.load(SAVE_DIR / \"best_model.pth\"))\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    logits, attn = model(torch.tensor(X).to(device))\n",
        "pred = binarize(logits).cpu().numpy()\n",
        "f1   = f1_score(y, pred)\n",
        "acc  = accuracy_score(y, pred)\n",
        "print(f\"\\nì „ì²´ ë°ì´í„° F1 = {f1:.4f}  ACC = {acc:.4f}\")\n",
        "\n",
        "# â–’â–’ 9) ë§ˆë¬´ë¦¬ ì €ì¥ â–’â–’â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "torch.save(model.state_dict(), SAVE_DIR / \"model_weights.pth\")\n",
        "print(\"\\nëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼\", SAVE_DIR / \"model_weights.pth\", \"ì— ì €ì¥ ì™„ë£Œ!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uY2QFZetURDE",
        "outputId": "4183eaf5-ecaf-4097-dc08-a16ec5c6d624"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   1/1000]  train:0.6878/0.797  val:0.6792/0.505\n",
            "[  50/1000]  train:0.0181/0.995  val:0.0252/0.995\n",
            "[ 100/1000]  train:0.0003/1.000  val:0.0422/0.995\n",
            "[ 150/1000]  train:0.0001/1.000  val:0.0538/0.995\n",
            "â†’ LR decay, now 1.0e-05\n",
            "[ 200/1000]  train:0.0000/1.000  val:0.0547/0.995\n",
            "\n",
            "â—† Early Stopping at epoch 201 (no val-loss improvement for 150 epochs)\n",
            "Best val loss: 0.02492677217445064\n",
            "\n",
            "ì „ì²´ ë°ì´í„° F1 = 0.9957  ACC = 0.9957\n",
            "\n",
            "ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ /content/drive/MyDrive/25-1-Bridge/OUTPUT/model_weights.pth ì— ì €ì¥ ì™„ë£Œ!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WQOHC02BA8cI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â–’â–’ 8) ì–´í…ì…˜ì´ ì§‘ì¤‘ëœ ë‹¨ì–´ í™•ì¸ â–’â–’â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def top_tokens(att_mat, tokens, topk=5):\n",
        "    \"\"\"\n",
        "    att_mat : (seq_len, hidden) â€“ í•œ ë¬¸ì¥ì„œ ê° í† í°ì˜ attention(ê°€ì¤‘ì¹˜) í–‰ë ¬\n",
        "    tokens  : í•´ë‹¹ ë¬¸ì¥ì˜ í† í° ë¦¬ìŠ¤íŠ¸\n",
        "    \"\"\"\n",
        "    scores = att_mat.sum(dim=1)                 # (seq_len,)\n",
        "    idxs   = torch.argsort(scores, descending=True)[:topk].tolist()\n",
        "    return [tokens[i] for i in idxs if i < len(tokens)]\n",
        "\n",
        "print(\"\\nğŸ“ ë¦¬ë·°ë³„ ìƒìœ„ Attention ë‹¨ì–´\")\n",
        "for i in range(20):   # ì• 5ë¬¸ì¥ë§Œ ì˜ˆì‹œ\n",
        "    words = top_tokens(attn[i], token_lists[i])\n",
        "    label = \"ê´‘ê³ \" if y[i] else \"ì¼ë°˜\"\n",
        "    print(f\"{i:02d} ({label}) â†’ {words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRNwm26abxac",
        "outputId": "72925d3e-f108-4e4c-ca4a-0e89e82186a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“ ë¦¬ë·°ë³„ ìƒìœ„ Attention ë‹¨ì–´\n",
            "00 (ê´‘ê³ ) â†’ ['ì •ë³´', 'ì¥ë‹¨ì ', 'ì•„ê³ ë‹¤', 'm', 'ìˆ˜ìˆ˜ë£Œ']\n",
            "01 (ê´‘ê³ ) â†’ ['KTX', 'ì•½', 'ì´ë™ë§Œ', 'ì›Œí¬ìƒµ', 'ë‚´ë¶€']\n",
            "02 (ê´‘ê³ ) â†’ ['ë‘¥ì§€', 'ë‚˜ì´ìŠ¤', 'ì›ë£¸', 'ì•ŠëŠ”', 'ë°©']\n",
            "03 (ê´‘ê³ ) â†’ ['ì œì£¼', 'ì œì£¼', 'ì¡°ì‹', 'ì œì£¼', 'ë¨¹ê³ ']\n",
            "04 (ê´‘ê³ ) â†’ ['ë§ˆì¼“', 'ì‰ë¼í†¤', 'íˆ¬ìˆ™', 'ìˆ™ë°•', 'ë‚ ']\n",
            "05 (ê´‘ê³ ) â†’ ['ë¶ˆí¸í•¨ì€', 'ì²´í—˜', 'í™ë³´', 'ì—¬í–‰', 'êµ³ì´']\n",
            "06 (ê´‘ê³ ) â†’ ['ìƒí™œ', 'LG', 'ì œì™¸', 'ë°˜ì…', 'ìŒë£Œ']\n",
            "07 (ê´‘ê³ ) â†’ ['ì²œì•ˆ', 'ê°‘ìê¸°', 'ì‰´', 'ì ˆì •', 'ì•±']\n",
            "08 (ê´‘ê³ ) â†’ ['ìš•ì¡°', 'ì–´', 'ì˜¤íˆë ¤', 'ëª©', 'ì»¤ì„œ']\n",
            "09 (ê´‘ê³ ) â†’ ['ì•ŠëŠ”', 'ì¸ê·¼', 'ì ', 'ê±´ë¬¼', 'ì£¼ì¤‘']\n",
            "10 (ê´‘ê³ ) â†’ ['ì„¼', 'ë“œë¦°ë“¯', 'ì—†ìœ¼ë‹ˆ', 'ì°¨ì—', 'ì—¬ê¸°ëŠ”']\n",
            "11 (ê´‘ê³ ) â†’ ['ìµì‚°', 'ìƒˆë¡œìš´', 'ì§€ì›', 'ë¹„', 'í–‰ë³µ']\n",
            "12 (ê´‘ê³ ) â†’ ['ë³„ë„', 'ë¹„ë°œë””', 'Ganglio', 'í™ì²œ', 'ì£¼ë°©']\n",
            "13 (ê´‘ê³ ) â†’ ['ë§í¬', 'ì ìš©', 'ì½”ë“œ', 'ìŠ¤í…Œì´', 'ëª©ìš•']\n",
            "14 (ê´‘ê³ ) â†’ ['ê²Œì„', 'ê´€ê´‘', 'ì˜¤í”ˆ', 'ìˆ˜ì˜', 'ê°€ëŠ”']\n",
            "15 (ê´‘ê³ ) â†’ ['ì²´í¬', 'ë·°', 'ë¦¼', 'ë·°', 'íŠ¸ìœˆ']\n",
            "16 (ê´‘ê³ ) â†’ ['ë¼ìš´ì§€', 'í¬í•¨', 'ë”°ë¡œ', 'ì„œìš¸', 'ê±´ë¬¼']\n",
            "17 (ê´‘ê³ ) â†’ ['ì—ì´ì¹˜', 'í•«', 'í”Œ', 'ì „ì£¼', 'ë°”']\n",
            "18 (ê´‘ê³ ) â†’ ['ê±´ì§€', 'ëŒ€ìš©', 'ì£¼ì°¨', 'ë‹´ìš”', 'ê·¸ëŸ¬ì„¸ìš”']\n",
            "19 (ê´‘ê³ ) â†’ ['í˜„ëŒ€', 'ê²°ì œ', 'í•´ì•¼', 'ì„ ', 'ì‚¬ëŒ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f18p8NQbB24n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# ì…€ 1: ì €ì¥ëœ ìµœì  ê°€ì¤‘ì¹˜ ë¡œë“œ í›„ validation(test) ì„±ëŠ¥ í™•ì¸\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "VAL_BATCH = 32                           # í•„ìš”í•˜ë©´ ì¡°ì •\n",
        "weights_path = SAVE_DIR / \"best_model.pth\"\n",
        "\n",
        "# 1) ëª¨ë¸ ì´ˆê¸°í™” & ê°€ì¤‘ì¹˜ ë¡œë“œ\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model_val = LSTMAttn().to(device)\n",
        "model_val.load_state_dict(torch.load(weights_path, map_location=device))\n",
        "model_val.eval()\n",
        "\n",
        "# 2) Validation DataLoader\n",
        "val_dl = DataLoader(ReviewDS(X_te, y_te), batch_size=VAL_BATCH)\n",
        "\n",
        "# 3) ì˜ˆì¸¡ & ì§€í‘œ ê³„ì‚°\n",
        "all_preds, all_trues = [], []\n",
        "with torch.no_grad():\n",
        "    for xb, yb in val_dl:\n",
        "        xb = xb.to(device)\n",
        "        logits, _ = model_val(xb)\n",
        "        preds = (torch.sigmoid(logits) > 0.5).cpu().int()\n",
        "        all_preds.append(preds)\n",
        "        all_trues.append(yb.int())\n",
        "all_preds = torch.cat(all_preds).numpy()\n",
        "all_trues = torch.cat(all_trues).numpy()\n",
        "\n",
        "f1  = f1_score(all_trues, all_preds)\n",
        "acc = accuracy_score(all_trues, all_preds)\n",
        "print(f\"[Validation] F1-score = {f1:.4f} | Accuracy = {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R552GPNiIGSn",
        "outputId": "fda2d2d1-4551-4c8f-9ab9-7e00d83a8eb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Validation] F1-score = 0.9952 | Accuracy = 0.9952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# ì…€ 2: ì „ì²´ ë¦¬ë·°ì— ëŒ€í•´ ê´‘ê³ ì¼ í™•ë¥ (prob_ad) ê³„ì‚°í•˜ì—¬ JSONì— ì¶”ê°€\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "FULL_BATCH = 256                        # GPU ë©”ëª¨ë¦¬ì— ë§ì¶° ì¡°ì •\n",
        "\n",
        "# 1) DataLoader êµ¬ì„±\n",
        "full_dl = DataLoader(ReviewDS(X, y), batch_size=FULL_BATCH)\n",
        "\n",
        "# 2) í™•ë¥  ì˜ˆì¸¡\n",
        "probs = []\n",
        "model_val.eval()\n",
        "with torch.no_grad():\n",
        "    for xb, _ in full_dl:\n",
        "        xb = xb.to(device)\n",
        "        logits, _ = model_val(xb)\n",
        "        p = torch.sigmoid(logits).cpu().numpy()    # (B,)\n",
        "        probs.extend(p.tolist())\n",
        "\n",
        "# 3) ì›ë³¸ DataFrameì— í™•ë¥  ì—´ ì¶”ê°€ í›„ í™•ì¸\n",
        "df_with_prob = df.copy()               # ê¸°ì¡´ df: review / label\n",
        "df_with_prob[\"prob_ad\"] = probs        # ad(1)ì¼ í™•ë¥ \n",
        "\n",
        "print(df_with_prob.head())\n",
        "\n",
        "# (ì„ íƒ) JSONìœ¼ë¡œ ì €ì¥í•˜ë ¤ë©´:\n",
        "output_json_path = SAVE_DIR / \"reviews_with_prob.json\"\n",
        "df_with_prob.to_json(output_json_path, orient=\"records\", force_ascii=False, indent=2)\n",
        "print(f\"\\nâœ“ í™•ë¥  ì¶”ê°€ JSON ì €ì¥: {output_json_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DO-mB4dIG9M",
        "outputId": "7e79a859-b3cb-48bf-caef-0261a21a2c64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review  label  prob_ad\n",
            "0  ë” ì¢‹ì€ ì—¬í–‰ ì •ë³´ë¥¼ ì œê³µí•˜ê¸° ìœ„í•´ \\nì•„ê³ ë‹¤ì™€ í•¨ê»˜ í•©ë‹ˆë‹¤.\\në³¸ ì½˜í…ì¸ ë¥¼ í†µí•œ ...      1      1.0\n",
            "1  ë©°ì¹  ì „ ì—¬ìˆ˜ë¡œ IP ì›Œí¬ìƒµì„ ë‹¤ë…€ì™”ë‹¤.\\në‹¹ì¼ ì˜¤í›„ 2ì‹œ ì›Œí¬ìƒµ ì‹œì‘ì´ë¼ ì˜¤ì „ ì‹œ...      1      1.0\n",
            "2  ì£¼ì˜\\nì´ ê¸€ì€ ë”ì´ìƒ ì‘ì„±í•˜ì§€ ì•ŠëŠ” ê¸€ì…ë‹ˆë‹¤. ì°¨í›„ ì‚­ì œ ë ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n[ì´ì „...      1      1.0\n",
            "3  ì œì£¼ ì›°ë‹ˆìŠ¤ WEí˜¸í…”\\në‹¤ì–‘í•œ íë§ í”„ë¡œê·¸ë¨ì´ ìˆëŠ” ì›°ë‹ˆìŠ¤ WEí˜¸í…”\\nWEí˜¸í…”\\nì œ...      1      1.0\n",
            "4  ë°©ì½•ì—¬í–‰ 3ì¼ì°¨ : í˜ë‹ŒìŠë¼ ë°©ì½• ì¡°ì‹ë·”í˜ - ë°©ì½• ì‰ë¼í†¤ ê·¸ëœë“œ ìˆ˜ì¿°ë¹— ìˆ™ë°• í›„ê¸°...      1      1.0\n",
            "\n",
            "âœ“ í™•ë¥  ì¶”ê°€ JSON ì €ì¥: /content/drive/MyDrive/25-1-Bridge/OUTPUT/reviews_with_prob.json\n"
          ]
        }
      ]
    }
  ]
}